{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8641721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81902fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgres henry123\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configurar una base de datos relacional PostgreSQL/SQL Server) y cargar los archivos CSV.\n",
    "# Setup config\n",
    "user = os.getenv('DB_USER') \n",
    "password = os.getenv('DB_PASSWORD')\n",
    "print(user + ' ' + password)\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "db_name = 'EcommerceDB'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89e4b757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql+psycopg2://postgres:henry123@localhost:5432/EcommerceDB\n"
     ]
    }
   ],
   "source": [
    "# Conexión a DB\n",
    "connection_string = f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{db_name}'\n",
    "print(connection_string)\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "746657ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: 10.ordenes_metodospago.csv | Hay duplicados?: False | Cantidad de duplicados: 0\n",
      "Archivo: 11.resenas_productos.csv | Hay duplicados?: False | Cantidad de duplicados: 0\n",
      "Archivo: 12.historial_pagos.csv | Hay duplicados?: False | Cantidad de duplicados: 0\n",
      "Archivo: 2.Usuarios.csv | Hay duplicados?: False | Cantidad de duplicados: 0\n",
      "Archivo: 3.Categorias.csv | Hay duplicados?: False | Cantidad de duplicados: 0\n",
      "Archivo: 4.Productos.csv | Hay duplicados?: False | Cantidad de duplicados: 0\n",
      "Archivo: 5.ordenes.csv | Hay duplicados?: False | Cantidad de duplicados: 0\n",
      "Archivo: 6.detalle_ordenes.csv | Hay duplicados?: False | Cantidad de duplicados: 0\n",
      "Archivo: 7.direcciones_envio.csv | Hay duplicados?: False | Cantidad de duplicados: 0\n",
      "Archivo: 8.carrito.csv | Hay duplicados?: False | Cantidad de duplicados: 0\n",
      "Archivo: 9.metodos_pago.csv | Hay duplicados?: False | Cantidad de duplicados: 0\n"
     ]
    }
   ],
   "source": [
    "# Buscar duplicados en los csvs\n",
    "archivos = os.listdir('../Files/csv')\n",
    "for archivo in archivos: \n",
    "    df = pd.read_csv('../Files/csv/' + archivo)\n",
    "    dupes_any = str(df.duplicated().any())\n",
    "    dupes_sum = str(df.duplicated().sum())\n",
    "    print('Archivo: ' + archivo + ' | Hay duplicados?: '+ dupes_any + ' | Cantidad de duplicados: ' + dupes_sum)\n",
    "\n",
    "# Al no haber duplicados, no hace falta limpiarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88f892a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion que itera sobre los nombres de archivos, transforma el nombre para \n",
    "# matchear el de las tablas creadas e inserta los datos del csv\n",
    "def cargar_csv_db(file):\n",
    "    # Leer el CSV\n",
    "    df = pd.read_csv('../Files/csv/' + file)\n",
    "    print(file + ' Leido!')\n",
    "    # Transformar el nombre del archivo\n",
    "    file = re.sub(r'csv', '', file, flags=re.IGNORECASE) \n",
    "    file = re.sub(r'[^a-zA-Z_]', '', file).lower()\n",
    "    print('Nombre archivo transformado: ' + file)\n",
    "    df.columns = df.columns.str.lower()  \n",
    "    # Cargar el csv a la tabla correspondiente\n",
    "    df.to_sql(file, engine, if_exists='append', index=False)\n",
    "    print('Datos insertados a tabla: ' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ddeb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar CSVs a tablas en EcommerceDB\n",
    "archivos = os.listdir('../Files/csv')\n",
    "for archivo in archivos:\n",
    "    try:\n",
    "        cargar_csv_db(archivo)\n",
    "    except Exception as e:\n",
    "        print('Error en la carga: ' + e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3283a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identificar columnas con datos semi-estructurados.\n",
    "# No hay\n",
    "\n",
    "#Aplicar transformaciones para convertir esas columnas a un formato estructurado adecuado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79789d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizar queries en SQL para examinar los datos y detectar posibles inconsistencias.\n",
    "\n",
    "#Implementar un análisis exploratorio de datos utilizando un ORM en Python (por ejemplo, SQLAlchemy o Django ORM).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac14a50",
   "metadata": {},
   "source": [
    "# Identificar llaves foráneas, atributos clave y columnas semi-estructuradas a transformar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95cff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar preprocesamiento para mejorar la calidad de los datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
